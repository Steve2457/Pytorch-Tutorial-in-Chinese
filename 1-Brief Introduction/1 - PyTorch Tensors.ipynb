{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们导入 PyTorch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch # 导入 PyTorch 库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们看一些基本的张量操作。首先，介绍几种创建张量的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros(5, 3) # 创建一个 5x3 的全零张量\n",
    "print(z)\n",
    "print(z.dtype) # 打印张量的数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面，我们创建了一个 5x3 的填充零的矩阵，并查询了它的数据类型，发现这些零是 32 位浮点数，这是 PyTorch 的默认设置。\n",
    "\n",
    "如果你想要整数怎么办？你可以随时覆盖默认设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "i = torch.ones((5, 3), dtype=torch.int16) # 创建一个 5x3 的全一张量，数据类型为 16 位整数\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以看到，当我们更改默认设置时，张量在打印时会清晰地报告这一点。\n",
    "\n",
    "通常会随机初始化学习权重，通常使用特定的 PRNG（伪随机数生成器）种子以确保结果的可重复性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random tensor:\n",
      "tensor([[0.3126, 0.3791],\n",
      "        [0.3087, 0.0736]])\n",
      "\n",
      "A different random tensor:\n",
      "tensor([[0.4216, 0.0691],\n",
      "        [0.2332, 0.4047]])\n",
      "\n",
      "Should match r1:\n",
      "tensor([[0.3126, 0.3791],\n",
      "        [0.3087, 0.0736]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729) # 设置随机种子以确保可重复性\n",
    "r1 = torch.rand(2, 2) # 创建一个 2x2 的随机张量\n",
    "print('一个随机张量:')\n",
    "print(r1)\n",
    "\n",
    "r2 = torch.rand(2, 2) # 创建另一个 2x2 的随机张量\n",
    "print('\\n另一个不同的随机张量:')\n",
    "print(r2) # 新的值\n",
    "\n",
    "torch.manual_seed(1729) # 重新设置相同的随机种子\n",
    "r3 = torch.rand(2, 2) # 再次创建随机张量\n",
    "print('\\n应该与 r1 匹配:')\n",
    "print(r3) # 由于重新设置种子，重复 r1 的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 张量直观地执行算术运算。形状相似的张量可以进行加法、乘法等运算。与标量的运算会分布到张量的每个元素上："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9675db506a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mr3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(2, 3) # 创建一个 2x3 的全一张量\n",
    "print(ones)\n",
    "\n",
    "twos = torch.ones(2, 3) * 2 # 每个元素乘以 2\n",
    "print(twos)\n",
    "\n",
    "threes = ones + twos       # 允许加法，因为形状相似\n",
    "print(threes)              # 张量按元素相加\n",
    "print(threes.shape)        # 结果张量与输入张量具有相同的维度\n",
    "\n",
    "r1 = torch.rand(2, 3) # 创建一个 2x3 的随机张量\n",
    "r2 = torch.rand(3, 2) # 创建一个 3x2 的随机张量\n",
    "# r3 = r1 + r2 # 这行会报错，因为形状不匹配无法进行元素级加法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是可用数学运算的一小部分示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random matrix, r:\n",
      "tensor([[-0.0022, -0.6116],\n",
      "        [-0.3071, -0.8297]])\n",
      "\n",
      "Absolute value of r:\n",
      "tensor([[0.0022, 0.6116],\n",
      "        [0.3071, 0.8297]])\n",
      "\n",
      "Inverse sine of r:\n",
      "tensor([[-0.0022, -0.6581],\n",
      "        [-0.3122, -0.9785]])\n",
      "\n",
      "Determinant of r:\n",
      "tensor(-0.1860)\n",
      "\n",
      "Singular value decomposition of r:\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.5599, -0.8286],\n",
      "        [-0.8286,  0.5599]]),\n",
      "S=tensor([1.0611, 0.1753]),\n",
      "V=tensor([[ 0.2410, -0.9705],\n",
      "        [ 0.9705,  0.2410]]))\n",
      "\n",
      "Average and standard deviation of r:\n",
      "(tensor(0.3608), tensor(-0.4376))\n",
      "\n",
      "Maximum value of r:\n",
      "tensor(-0.0022)\n"
     ]
    }
   ],
   "source": [
    "r = torch.rand(2, 2) - 0.5 * 2 # 创建一个值在 -1 和 1 之间的 2x2 随机张量\n",
    "print('一个随机矩阵, r:')\n",
    "print(r)\n",
    "\n",
    "# 支持常见的数学运算:\n",
    "print('\\nr 的绝对值:')\n",
    "print(torch.abs(r)) # 计算绝对值\n",
    "\n",
    "# ...以及三角函数:\n",
    "print('\\nr 的反正弦:')\n",
    "print(torch.asin(r)) # 计算反正弦\n",
    "\n",
    "# ...以及线性代数运算，如行列式和奇异值分解\n",
    "print('\\nr 的行列式:')\n",
    "print(torch.det(r)) # 计算行列式\n",
    "print('\\nr 的奇异值分解:')\n",
    "print(torch.svd(r)) # 计算奇异值分解\n",
    "\n",
    "# ...以及统计和聚合运算:\n",
    "print('\\nr 的平均值和标准差:')\n",
    "print(torch.std_mean(r)) # 计算标准差和均值\n",
    "print('\\nr 的最大值:')\n",
    "print(torch.max(r)) # 计算最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于 PyTorch 张量的强大功能还有很多需要了解，包括如何设置它们以在 GPU 上进行并行计算——我们将在另一个视频中更深入地探讨。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
