{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在 PyTorch 中训练您的模型\n",
    "## 简介\n",
    "在之前的视频中，我们已经讨论并演示了：\n",
    "* 使用 torch.nn 模块的神经网络层和函数构建模型\n",
    "* 自动梯度计算的机制，这是基于梯度的模型训练的核心\n",
    "* 使用 TensorBoard 可视化训练进度和其他活动\n",
    "\n",
    "在本视频中，我们将为您的工具库添加一些新工具：\n",
    "* 我们将熟悉数据集和数据加载器抽象，以及它们如何简化在训练循环中向模型提供数据的过程\n",
    "* 我们将讨论特定的损失函数以及何时使用它们\n",
    "* 我们将了解 PyTorch 优化器，它实现了根据损失函数的结果调整模型权重的算法\n",
    "\n",
    "最后，我们将把这些工具结合起来，看看完整的 PyTorch 训练循环是如何运行的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集和数据加载器\n",
    "\n",
    "`Dataset` 和 `DataLoader` 类封装了从存储中提取数据并以批量形式将其暴露给训练循环的过程。\n",
    "\n",
    "`Dataset` 负责访问和处理单个数据实例。\n",
    "\n",
    "`DataLoader` 从 `Dataset` 中提取数据实例（可以自动或使用您定义的采样器），将它们收集成批量，并返回供训练循环使用。`DataLoader` 可以处理各种类型的数据集，无论它们包含何种类型的数据。\n",
    "\n",
    "在本教程中，我们将使用 TorchVision 提供的 Fashion-MNIST 数据集。我们使用 `torchvision.transforms.Normalize()` 对图像内容进行零中心化和归一化，并下载训练和验证数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard 支持\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])  # 归一化图像数据\n",
    "\n",
    "# 创建训练和验证数据集，如有必要则下载\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# 为数据集创建数据加载器；训练数据需要打乱，验证数据不需要\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# 类别标签\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# 报告数据集大小\n",
    "print('训练集包含 {} 个实例'.format(len(training_set)))\n",
    "print('验证集包含 {} 个实例'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和往常一样，让我们可视化数据以进行合理性检查："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandal  Shirt  Shirt  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 用于内联显示图像的辅助函数\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # 反归一化\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 从图像创建网格并显示\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))  # 打印图像对应的类别标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型\n",
    "\n",
    "在本示例中，我们将使用 LeNet-5 的一个变体模型——如果您观看过本系列的前几期视频，这应该很熟悉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch 模型继承自 torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "\n",
    "在本示例中，我们将使用交叉熵损失。为了演示，我们将创建虚拟输出和标签值的批次，通过损失函数运行它们，并检查结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7915, 0.4766, 0.3735, 0.5340, 0.0799, 0.9948, 0.1870, 0.0507, 0.1183,\n",
      "         0.9106],\n",
      "        [0.9666, 0.3765, 0.4324, 0.7354, 0.1953, 0.8906, 0.6882, 0.1925, 0.7076,\n",
      "         0.8777],\n",
      "        [0.4412, 0.0325, 0.4886, 0.9350, 0.9792, 0.5580, 0.6199, 0.2478, 0.3619,\n",
      "         0.8307],\n",
      "        [0.3287, 0.8571, 0.6046, 0.6719, 0.5982, 0.0540, 0.7193, 0.4764, 0.7451,\n",
      "         0.8345]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.196722984313965\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 注意：损失函数期望数据以批次形式提供，因此我们创建了 4 个批次\n",
    "# 表示模型对每个输入在 10 个类别中的置信度\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# 表示测试的 10 个类别中的正确类别\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "    \n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('此批次的总损失：{}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "\n",
    "在本示例中，我们将使用简单的[随机梯度下降](https://pytorch.org/docs/stable/optim.html)（带动量）。\n",
    "\n",
    "尝试一些优化方案的变化可能会很有启发：\n",
    "* 学习率决定了优化器采取的步长大小。不同的学习率对训练结果有什么影响，包括准确性和收敛时间？\n",
    "* 动量在多个步骤中将优化器推向最强梯度的方向。改变这个值对结果有什么影响？\n",
    "* 尝试一些不同的优化算法，例如平均 SGD、Adagrad 或 Adam。结果有何不同？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器在 torch.optim 包中指定\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练循环\n",
    "\n",
    "下面是一个执行一个训练周期的函数。它枚举来自 DataLoader 的数据，并在每次循环中执行以下操作：\n",
    "* 从 DataLoader 获取一批训练数据\n",
    "* 清零优化器的梯度\n",
    "* 执行推理——即从模型获取输入批次的预测\n",
    "* 计算该组预测与数据集标签之间的损失\n",
    "* 计算学习权重的反向梯度\n",
    "* 告诉优化器执行一个学习步骤——即根据该批次的观察梯度调整模型的学习权重，按照我们选择的优化算法\n",
    "* 每 1000 个批次报告一次损失。\n",
    "* 最后，报告最后 1000 个批次的平均每批次损失，以便与验证运行进行比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    \n",
    "    # 在这里，我们使用 enumerate(training_loader) 而不是\n",
    "    # iter(training_loader)，以便跟踪批次索引并进行一些周期内报告\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # 每个数据实例都是一个输入 + 标签对\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # 每批次清零梯度！\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 为此批次进行预测\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 计算损失及其梯度\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 调整学习权重\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 收集数据并报告\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # 每批次损失\n",
    "            print('  批次 {} 损失：{}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "            \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 每周期活动\n",
    "\n",
    "每个周期我们需要做一些事情：\n",
    "* 通过检查未用于训练的数据集上的相对损失进行验证，并报告结果\n",
    "* 保存模型的副本\n",
    "\n",
    "在这里，我们将在 TensorBoard 中进行报告。这需要转到命令行启动 TensorBoard，并在另一个浏览器标签中打开它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在单独的单元中初始化，以便轻松向同一运行添加更多周期\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6:\n",
      "  batch 1000 loss: 0.2712569512435075\n",
      "  batch 2000 loss: 0.2601859306513652\n",
      "  batch 3000 loss: 0.259985514376438\n",
      "  batch 4000 loss: 0.2620664734886377\n",
      "  batch 5000 loss: 0.25726098109555096\n",
      "  batch 6000 loss: 0.2829849383759356\n",
      "  batch 7000 loss: 0.2504337926213739\n",
      "  batch 8000 loss: 0.28633546594417153\n",
      "  batch 9000 loss: 0.2615796004622789\n",
      "  batch 10000 loss: 0.27075869734541264\n",
      "  batch 11000 loss: 0.26998766335008256\n",
      "  batch 12000 loss: 0.2614513303764511\n",
      "  batch 13000 loss: 0.25101113697645633\n",
      "  batch 14000 loss: 0.2572545314691452\n",
      "  batch 15000 loss: 0.2646196218387686\n",
      "LOSS train 0.2646196218387686 valid 0.3120253086090088\n",
      "EPOCH 7:\n",
      "  batch 1000 loss: 0.23217408991576668\n",
      "  batch 2000 loss: 0.26750317257382084\n",
      "  batch 3000 loss: 0.2423647686961576\n",
      "  batch 4000 loss: 0.247761928711403\n",
      "  batch 5000 loss: 0.2550650118602407\n",
      "  batch 6000 loss: 0.2383200812106561\n",
      "  batch 7000 loss: 0.24519096856425546\n",
      "  batch 8000 loss: 0.26013731523246864\n",
      "  batch 9000 loss: 0.2632041203577719\n",
      "  batch 10000 loss: 0.2694681866055953\n",
      "  batch 11000 loss: 0.2497381271280392\n",
      "  batch 12000 loss: 0.258198305114337\n",
      "  batch 13000 loss: 0.25165209144220446\n",
      "  batch 14000 loss: 0.24501102960605475\n",
      "  batch 15000 loss: 0.2714995371173936\n",
      "LOSS train 0.2714995371173936 valid 0.29794615507125854\n",
      "EPOCH 8:\n",
      "  batch 1000 loss: 0.23320657860705432\n",
      "  batch 2000 loss: 0.24858402526881765\n",
      "  batch 3000 loss: 0.2317633100426342\n",
      "  batch 4000 loss: 0.23152679081074393\n",
      "  batch 5000 loss: 0.25687610574232167\n",
      "  batch 6000 loss: 0.24898936196635713\n",
      "  batch 7000 loss: 0.24102263286134393\n",
      "  batch 8000 loss: 0.221216088422334\n",
      "  batch 9000 loss: 0.24839843582039622\n",
      "  batch 10000 loss: 0.25535652273873394\n",
      "  batch 11000 loss: 0.2364917180010475\n",
      "  batch 12000 loss: 0.24013902479332047\n",
      "  batch 13000 loss: 0.2527130251531107\n",
      "  batch 14000 loss: 0.2268015396361734\n",
      "  batch 15000 loss: 0.23084795617466533\n",
      "LOSS train 0.23084795617466533 valid 0.30887657403945923\n",
      "EPOCH 9:\n",
      "  batch 1000 loss: 0.20914060916691596\n",
      "  batch 2000 loss: 0.2383922872493049\n",
      "  batch 3000 loss: 0.24150142164375699\n",
      "  batch 4000 loss: 0.22258911576591162\n",
      "  batch 5000 loss: 0.20668142405075765\n",
      "  batch 6000 loss: 0.23581195026773002\n",
      "  batch 7000 loss: 0.22473419379490223\n",
      "  batch 8000 loss: 0.24462740539792072\n",
      "  batch 9000 loss: 0.23375550449842103\n",
      "  batch 10000 loss: 0.2425170969904384\n",
      "  batch 11000 loss: 0.23850887738823257\n",
      "  batch 12000 loss: 0.24902974063844113\n",
      "  batch 13000 loss: 0.23447657160507732\n",
      "  batch 14000 loss: 0.22578069565728948\n",
      "  batch 15000 loss: 0.22243430260214883\n",
      "LOSS train 0.22243430260214883 valid 0.3069189786911011\n",
      "EPOCH 10:\n",
      "  batch 1000 loss: 0.222734550482106\n",
      "  batch 2000 loss: 0.22249747196489136\n",
      "  batch 3000 loss: 0.22432524254382952\n",
      "  batch 4000 loss: 0.20827693899664973\n",
      "  batch 5000 loss: 0.2167568837881121\n",
      "  batch 6000 loss: 0.22029019777785727\n",
      "  batch 7000 loss: 0.21953412261475375\n",
      "  batch 8000 loss: 0.21163398088562416\n",
      "  batch 9000 loss: 0.21914111551065799\n",
      "  batch 10000 loss: 0.215088521746859\n",
      "  batch 11000 loss: 0.23400862988600693\n",
      "  batch 12000 loss: 0.21626755150469398\n",
      "  batch 13000 loss: 0.24138166160018262\n",
      "  batch 14000 loss: 0.25017317488135904\n",
      "  batch 15000 loss: 0.2206965961180249\n",
      "LOSS train 0.2206965961180249 valid 0.3038918077945709\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('周期 {}:'.format(epoch_number + 1))\n",
    "    \n",
    "    # 确保梯度跟踪已打开，并对数据进行一次遍历\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    \n",
    "    # 我们不需要梯度来进行报告\n",
    "    model.train(False)\n",
    "    \n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "    \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('损失 训练 {} 验证 {}'.format(avg_loss, avg_vloss))\n",
    "    \n",
    "    # 记录每批次平均损失\n",
    "    # 包括训练和验证\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    # 跟踪最佳性能，并保存模型状态\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要加载模型的保存版本：\n",
    "\n",
    "```\n",
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(PATH))\n",
    "```\n",
    "\n",
    "加载模型后，它可以用于任何您需要的任务——进一步训练、推理或分析。\n",
    "\n",
    "请注意，如果您的模型具有影响模型结构的构造参数，则需要提供这些参数并以与保存时相同的方式配置模型。\n",
    "\n",
    "## 其他资源\n",
    "\n",
    "* [数据工具](https://pytorch.org/docs/stable/data.html) 的文档，包括 Dataset 和 DataLoader，位于 pytorch.org\n",
    "* 关于 [固定内存的使用](https://pytorch.org/docs/stable/notes/cuda.html#cuda-memory-pinning) 的说明，用于 GPU 训练\n",
    "* [TorchVision](https://pytorch.org/docs/stable/torchvision/datasets.html)、[TorchText](https://pytorch.org/text/datasets.html) 和 [TorchAudio](https://pytorch.org/audio/datasets.html) 中可用数据集的文档\n",
    "* PyTorch 中可用的 [损失函数](https://pytorch.org/docs/stable/nn.html#loss-functions) 的文档\n",
    "* [torch.optim 包](https://pytorch.org/docs/stable/optim.html) 的文档，其中包括优化器和相关工具，例如学习率调度\n",
    "* 关于保存和加载模型的详细 [教程](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "* [pytorch.org 的教程部分](https://pytorch.org/tutorials/) 包含关于各种训练任务的教程，包括不同领域的分类、生成对抗网络、强化学习等"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
